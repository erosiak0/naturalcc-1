[32m[2023-05-06 15:36:27]    INFO >> Load arguments in /home/erosiak/workspace/naturalcc/run/summarization/neural_transformer/relative/python_wan/python.yml (train.py:290, cli_main())[0m
[32m[2023-05-06 15:36:27]    INFO >> {'criterion': 'neural_transformer', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 500, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 0, 'fp16_no_flatten_grads': 0, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'be_summarization', 'seed': 1, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'bf16': 0, 'memory_efficient_bf16': 0, 'server_ip': '', 'server_port': ''}, 'dataset': {'num_workers': 3, 'skip_invalid_size_inputs_valid_test': 1, 'max_tokens': None, 'max_sentences': 32, 'required_batch_size_multiple': 1, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 128, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'pipeline_model_parallel': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/home/erosiak/data_naturalcc/python_wan/summarization/data-mmap', 'source_lang': 'code_tokens', 'target_lang': 'docstring_tokens', 'load_alignments': 0, 'left_pad_source': 0, 'left_pad_target': 0, 'max_source_positions': 400, 'max_target_positions': 32, 'upsample_primary': 1, 'truncate_source': 5, 'truncate_target': 5, 'eval_bleu': 1, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 1}, 'model': {'arch': 'neural_transformer', 'offset_positions_by_padding': 0, 'pooler_dropout': 0.2, 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.2, 'activation_dropout': 0.2, 'relu_dropout': 0.2, 'encoder_positional_embeddings': 1, 'encoder_learned_pos': 1, 'encoder_max_relative_len': 32, 'encoder_embed_path': 0, 'encoder_embed_dim': 512, 'encoder_ffn_embed_dim': 2048, 'encoder_layers': 6, 'encoder_attention_heads': 8, 'encoder_normalize_before': 0, 'encoder_position_encoding_version': 'ncc_learned', 'decoder_position_encoding_version': 'ncc_learned', 'multihead_attention_version': 'ncc', 'decoder_embed_path': '', 'decoder_positional_embeddings': 1, 'decoder_learned_pos': 1, 'decoder_max_relative_len': 0, 'decoder_embed_dim': 512, 'decoder_output_dim': 512, 'decoder_input_dim': 512, 'decoder_ffn_embed_dim': 2048, 'decoder_layers': 6, 'decoder_attention_heads': 8, 'decoder_normalize_before': 0, 'no_decoder_final_norm': 0, 'adaptive_softmax_cutoff': None, 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 0.0, 'share_decoder_input_output_embed': 1, 'share_all_embeddings': 0, 'adaptive_input': 0, 'adaptive_input_factor': 0.0, 'adaptive_input_cutoff': None, 'tie_adaptive_weights': 0, 'tie_adaptive_proj': 0, 'no_cross_attention': 0, 'cross_self_attention': 0, 'layer_wise_attention': 0, 'encoder_layerdrop': 0.0, 'decoder_layerdrop': 0.0, 'encoder_layers_to_keep': None, 'decoder_layers_to_keep': None, 'layernorm_embedding': 0, 'no_scale_embedding': 1, 'encoder_dropout_in': 0.2, 'encoder_dropout_out': 0.2, 'decoder_dropout_in': 0.2, 'decoder_dropout_out': 0.2, 'max_source_positions': 400, 'max_target_positions': 32}, 'optimization': {'max_epoch': 200, 'max_update': 0, 'clip_norm': 5, 'update_freq': [1], 'lrs': [0.0001], 'min_lr': -1, 'use_bmuf': 0, 'force_anneal': 0, 'warmup_updates': 0, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000, 'sentence_avg': 1, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 1}, 'sgd': {'momentum': 0, 'weight_decay': 0, 'dampening': 0, 'nesterov': 0}, 'lr_shrink': 0.99}, 'checkpoint': {'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 1, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': 1, 'patience': -1, 'save_dir': '/home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/relative_transformer/checkpoints', 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/relative_transformer/checkpoints/checkpoint_best.pt', 'remove_bpe': None, 'quiet': 0, 'results_path': '/home/erosiak/data_naturalcc/python_wan/', 'model_overrides': '{}', 'max_sentences': 32, 'beam': 5, 'nbest': 31, 'max_len_a': 0, 'max_len_b': 30, 'min_len': 10, 'match_source_len': 0, 'no_early_stop': 1, 'unnormalized': 0, 'no_beamable_mm': 0, 'lenpen': 1.3, 'unkpen': 0, 'replace_unk': None, 'sacrebleu': 0, 'score_reference': 0, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': 0, 'sampling_topk': -1, 'sampling_topp': -1, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 1, 'print_step': 0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': 0, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': 0, 'retain_iter_history': 0, 'decoding_format': None, 'nltk_bleu': 1, 'rouge': 1}} (train.py:292, cli_main())[0m
[32m[2023-05-06 15:36:27]    INFO >> single GPU training... (train.py:321, cli_main())[0m
[32m[2023-05-06 15:36:27]    INFO >> [code_tokens] dictionary: 50000 types (be_summarization.py:124, setup_task())[0m
[32m[2023-05-06 15:36:27]    INFO >> [docstring_tokens] dictionary: 30000 types (be_summarization.py:125, setup_task())[0m
[32m[2023-05-06 15:36:27]    INFO >> truncate valid.code_tokens to 400 (be_summarization.py:60, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:27]    INFO >> truncate valid.docstring_tokens to 30 (be_summarization.py:68, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:27]    INFO >> loaded 18505 examples from: /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/valid.code_tokens (be_summarization.py:77, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:27]    INFO >> loaded 18505 examples from: /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/valid.docstring_tokens (be_summarization.py:78, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:27]    INFO >> NeuralTransformer(
  (encoder): NeuralTransformerEncoder(
    (embed_tokens): Embedding(50000, 512, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(400, 512)
    (layers): ModuleList(
      (0): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (1): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (2): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (3): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (4): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (5): NeuralTransformerEncoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
          (relative_position_keys): Embedding(65, 64)
          (relative_position_values): Embedding(65, 64)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
    )
  )
  (decoder): NeuralTransformerDecoder(
    (embed_tokens): Embedding(30000, 512, padding_idx=0)
    (embed_positions): LearnedPositionalEmbedding(32, 512)
    (layers): ModuleList(
      (0): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (1): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (2): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (3): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (4): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
      (5): NueralTransformerDecoderLayer(
        (self_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (encoder_attn): RelativeMultiheadAttention(
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (ff_layer_norm): LayerNorm((512,), eps=1e-08, elementwise_affine=True)
      )
    )
  )
) (train.py:211, single_main())[0m
[32m[2023-05-06 15:36:27]    INFO >> model neural_transformer, criterion NeuralTransformerCriterion (train.py:212, single_main())[0m
[32m[2023-05-06 15:36:27]    INFO >> num. model params: 85399600 (num. trained: 85399600) (train.py:213, single_main())[0m
[32m[2023-05-06 15:36:28]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:530, pretty_print_cuda_env_list())[0m
[32m[2023-05-06 15:36:28]    INFO >> rank   0: capabilities =  8.6  ; total memory = 12288 MB ; free memory = 10554 MB ; used memory = 1733 MB ; name = NVIDIA GeForce RTX 3060                  (utils.py:532, pretty_print_cuda_env_list())[0m
[32m[2023-05-06 15:36:28]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:540, pretty_print_cuda_env_list())[0m
[32m[2023-05-06 15:36:28]    INFO >> training on 1 GPUs (train.py:220, single_main())[0m
[32m[2023-05-06 15:36:28]    INFO >> max tokens per GPU = None and max sentences per GPU = 32 (train.py:221, single_main())[0m
[32m[2023-05-06 15:36:28]    INFO >> no existing checkpoint found /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/relative_transformer/checkpoints/checkpoint_last.pt (ncc_trainers.py:299, load_checkpoint())[0m
[32m[2023-05-06 15:36:28]    INFO >> loading train data for epoch 1 (ncc_trainers.py:314, get_train_iterator())[0m
[32m[2023-05-06 15:36:28]    INFO >> truncate train.code_tokens to 400 (be_summarization.py:60, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:28]    INFO >> truncate train.docstring_tokens to 30 (be_summarization.py:68, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:28]    INFO >> loaded 55538 examples from: /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/train.code_tokens (be_summarization.py:77, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:28]    INFO >> loaded 55538 examples from: /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/train.docstring_tokens (be_summarization.py:78, load_langpair_dataset())[0m
[32m[2023-05-06 15:36:28]    INFO >> NOTE: your device may support faster training with fp16 or --amp (ncc_trainers.py:183, _setup_optimizer())[0m
/home/erosiak/workspace/naturalcc/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
[32m[2023-05-06 15:38:19]    INFO >> epoch 001:    500 / 1736 loss=101.411, nll_loss=9.715, bleu=0, ppl=840.44, wps=1576.3, ups=4.72, wpb=334, bsz=32, num_updates=500, lr=0.0001, gnorm=41.983, clip=100, train_wall=106, gb_free=9.2, wall=110 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:40:06]    INFO >> epoch 001:   1000 / 1736 loss=87.544, nll_loss=8.408, bleu=0, ppl=339.66, wps=1547.8, ups=4.65, wpb=333.2, bsz=32, num_updates=1000, lr=0.0001, gnorm=27.546, clip=100, train_wall=107, gb_free=9.2, wall=218 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:41:55]    INFO >> epoch 001:   1500 / 1736 loss=85.157, nll_loss=8.199, bleu=0, ppl=293.84, wps=1524, ups=4.59, wpb=332.4, bsz=32, num_updates=1500, lr=0.0001, gnorm=31.162, clip=100, train_wall=108, gb_free=9.5, wall=327 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:42:48]    INFO >> epoch 001 | loss 90.456 | nll_loss 8.682 | bleu 0 | ppl 410.82 | wps 1542.5 | ups 4.63 | wpb 333.3 | bsz 32 | num_updates 1736 | lr 0.0001 | gnorm 35.174 | clip 100 | train_wall 372 | gb_free 10.1 | wall 380 (progress_bar.py:267, print())[0m
[32m[2023-05-06 15:45:09]    INFO >> epoch 001 | valid on 'valid' subset | loss 83.417 | nll_loss 7.992 | bleu 13.1672 | ppl 254.59 | wps 1411.8 | wpb 1332 | bsz 127.6 | num_updates 1736 (progress_bar.py:267, print())[0m
[32m[2023-05-06 15:45:10]    INFO >> saved checkpoint /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/relative_transformer/checkpoints/checkpoint_best.pt (epoch 1 @ 1736 updates, score 13.167241) (writing took 0.796786 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[32m[2023-05-06 15:46:10]    INFO >> epoch 002:    264 / 1736 loss=83.727, nll_loss=7.997, bleu=0, ppl=255.47, wps=656.1, ups=1.96, wpb=334.7, bsz=32, num_updates=2000, lr=0.0001, gnorm=55.491, clip=100, train_wall=109, gb_free=9.2, wall=582 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:47:52]    INFO >> epoch 002:    764 / 1736 loss=81.246, nll_loss=7.81, bleu=0, ppl=224.46, wps=1634.2, ups=4.91, wpb=332.9, bsz=32, num_updates=2500, lr=0.0001, gnorm=123.123, clip=100, train_wall=101, gb_free=9.2, wall=684 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:49:34]    INFO >> epoch 002:   1264 / 1736 loss=81.395, nll_loss=7.841, bleu=0, ppl=229.22, wps=1633.5, ups=4.92, wpb=332.2, bsz=32, num_updates=3000, lr=0.0001, gnorm=177.775, clip=100, train_wall=101, gb_free=9.4, wall=786 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:51:10]    INFO >> epoch 002 | loss 81.735 | nll_loss 7.845 | bleu 0 | ppl 229.98 | wps 1153.3 | ups 3.46 | wpb 333.3 | bsz 32 | num_updates 3472 | lr 0.0001 | gnorm 164.543 | clip 100 | train_wall 353 | gb_free 10.1 | wall 881 (progress_bar.py:267, print())[0m
[32m[2023-05-06 15:53:15]    INFO >> epoch 002 | valid on 'valid' subset | loss 82.069 | nll_loss 7.863 | bleu 15.5866 | ppl 232.79 | wps 1578.9 | wpb 1332 | bsz 127.6 | num_updates 3472 | best_bleu 15.5866 (progress_bar.py:267, print())[0m
[32m[2023-05-06 15:53:17]    INFO >> saved checkpoint /home/erosiak/data_naturalcc/python_wan/summarization/data-mmap/relative_transformer/checkpoints/checkpoint_best.pt (epoch 2 @ 3472 updates, score 15.586621) (writing took 1.219363 seconds) (checkpoint_utils.py:78, save_checkpoint())[0m
[32m[2023-05-06 15:53:26]    INFO >> epoch 003:     28 / 1736 loss=81.747, nll_loss=7.841, bleu=0, ppl=229.25, wps=719, ups=2.16, wpb=333.3, bsz=32, num_updates=3500, lr=9.9e-05, gnorm=260.104, clip=100, train_wall=100, gb_free=9.4, wall=1018 (progress_bar.py:258, log())[0m
[32m[2023-05-06 15:55:07]    INFO >> epoch 003:    528 / 1736 loss=80.682, nll_loss=7.725, bleu=0, ppl=211.62, wps=1646.9, ups=4.93, wpb=334.2, bsz=32, num_updates=4000, lr=9.9e-05, gnorm=809.336, clip=100, train_wall=101, gb_free=9.6, wall=1119 (progress_bar.py:258, log())[0m
Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/erosiak/workspace/naturalcc/run/summarization/neural_transformer/train.py", line 326, in <module>
    cli_main()
  File "/home/erosiak/workspace/naturalcc/run/summarization/neural_transformer/train.py", line 322, in cli_main
    single_main(args)
  File "/home/erosiak/workspace/naturalcc/run/summarization/neural_transformer/train.py", line 242, in single_main
    train(args, trainer, task, epoch_itr)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/erosiak/workspace/naturalcc/run/summarization/neural_transformer/train.py", line 54, in train
    log_output = trainer.train_step(samples)
  File "/usr/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/home/erosiak/workspace/naturalcc/ncc/trainers/ncc_trainers.py", line 377, in train_step
    loss, sample_size_i, logging_output = self.task.train_step(
  File "/home/erosiak/workspace/naturalcc/ncc/tasks/summarization/be_summarization.py", line 239, in train_step
    optimizer.backward(loss)
  File "/home/erosiak/workspace/naturalcc/ncc/optimizers/ncc_optimizer.py", line 85, in backward
    loss.backward()
  File "/home/erosiak/venvs/38_naturalcc/lib/python3.8/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/erosiak/venvs/38_naturalcc/lib/python3.8/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
